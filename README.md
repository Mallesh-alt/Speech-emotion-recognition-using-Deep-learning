🌍 Multilingual Speech Emotion Recognition 🎙️🧠

A machine learning project for detecting emotions from speech across multiple languages using advanced audio processing and deep learning techniques.

📌 Project Overview

This project classifies emotions from speech audio samples in multiple languages. It extracts key audio features and utilizes machine learning and deep learning techniques for multilingual emotion classification.

🚀 Features

✅ Supports multiple languages (e.g., English, Spanish, French, etc.).

✅ Classifies various emotions (e.g., happy, sad, angry, neutral).

✅ Uses MFCC, Chroma, and Spectrograms for feature extraction.

✅ Implements CNN, LSTM, or Transformer-based models.

✅ Can be expanded for real-time emotion detection.

📂 Datasets

The Toronto Emotional Speech Set (TESS) dataset consists of speech samples from two female actors, simulating different emotions while reading given sentences

🛠️ Installation

Clone the repository:



cd multilingual-speech-emotion

Install dependencies: pip install -r requirements.txt

📊 Model Training

Feature Extraction: Uses Librosa to extract MFCCs, Chroma, and Mel-Spectrograms.

Machine Learning Models: SVM, Random Forest, XGBoost.

Deep Learning Models: CNN, LSTM, Transformer-based architectures.

📈 Results

The model achieves high accuracy in multilingual emotion recognition, with potential for real-time applications.

🤖 Future Improvements

Integrate real-time multilingual emotion detection. Expand dataset to include more diverse languages and speakers. Optimize deep learning models for faster inference.

📝 License

This project is open-source and available under the MIT License.
