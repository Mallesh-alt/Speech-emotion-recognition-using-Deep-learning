ğŸŒ Multilingual Speech Emotion Recognition ğŸ™ï¸ğŸ§ 

A machine learning project for detecting emotions from speech across multiple languages using advanced audio processing and deep learning techniques.

ğŸ“Œ Project Overview

This project classifies emotions from speech audio samples in multiple languages. It extracts key audio features and utilizes machine learning and deep learning techniques for multilingual emotion classification.

ğŸš€ Features

âœ… Supports multiple languages (e.g., English, Spanish, French, etc.).

âœ… Classifies various emotions (e.g., happy, sad, angry, neutral).

âœ… Uses MFCC, Chroma, and Spectrograms for feature extraction.

âœ… Implements CNN, LSTM, or Transformer-based models.

âœ… Can be expanded for real-time emotion detection.

ğŸ“‚ Datasets

The Toronto Emotional Speech Set (TESS) dataset consists of speech samples from two female actors, simulating different emotions while reading given sentences

ğŸ› ï¸ Installation

Clone the repository:



cd multilingual-speech-emotion

Install dependencies: pip install -r requirements.txt

ğŸ“Š Model Training

Feature Extraction: Uses Librosa to extract MFCCs, Chroma, and Mel-Spectrograms.

Machine Learning Models: SVM, Random Forest, XGBoost.

Deep Learning Models: CNN, LSTM, Transformer-based architectures.

ğŸ“ˆ Results

The model achieves high accuracy in multilingual emotion recognition, with potential for real-time applications.

ğŸ¤– Future Improvements

Integrate real-time multilingual emotion detection. Expand dataset to include more diverse languages and speakers. Optimize deep learning models for faster inference.

ğŸ“ License

This project is open-source and available under the MIT License.
